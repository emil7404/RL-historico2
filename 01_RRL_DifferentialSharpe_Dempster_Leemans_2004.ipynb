{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240da6e0",
   "metadata": {},
   "source": [
    "\n",
    "# RRL con Sharpe Diferencial (Dempster & Leemans, 2004)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fbf171",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(7)\n",
    "n = 5000\n",
    "steps = np.random.normal(0, 0.001, size=n)\n",
    "regime = np.sign(np.sin(np.linspace(0, 30, n))) * 0.0007\n",
    "price = 100*np.ones(n)\n",
    "for t in range(1, n):\n",
    "    price[t] = price[t-1]*(1+steps[t]+regime[t])\n",
    "df = pd.DataFrame({\"close\": price})\n",
    "df[\"ret\"] = df[\"close\"].pct_change().fillna(0.0)\n",
    "\n",
    "M = 10\n",
    "for i in range(1, M+1):\n",
    "    df[f\"ret_lag_{i}\"] = df[\"ret\"].shift(i).fillna(0.0)\n",
    "df = df.iloc[M+1:].reset_index(drop=True)\n",
    "\n",
    "X = df[[f\"ret_lag_{i}\" for i in range(1, M+1)]].values.astype(np.float64)\n",
    "r = df[\"ret\"].values.astype(np.float64)\n",
    "\n",
    "T = len(df)\n",
    "delta = 0.0001\n",
    "eta_sr = 0.01\n",
    "lr = 0.05\n",
    "epochs = 3\n",
    "\n",
    "w = np.zeros(M+2)\n",
    "\n",
    "def policy(x, prevF):\n",
    "    z = np.dot(w[:M], x) + w[M]*prevF + w[M+1]\n",
    "    f = np.tanh(z)\n",
    "    F = np.sign(f + 1e-8)\n",
    "    return f, F, z\n",
    "\n",
    "def train(X, r, epochs):\n",
    "    global w\n",
    "    A = 0.0; B = 1e-6\n",
    "    prevF_exec = 0.0\n",
    "    prevF_cont = 0.0\n",
    "    for ep in range(epochs):\n",
    "        dL = np.zeros_like(w)\n",
    "        for t in range(len(X)):\n",
    "            f_cont, F_exec, z = policy(X[t], prevF_cont)\n",
    "            Rt = prevF_exec*r[t] - delta*abs(F_exec - prevF_exec)\n",
    "            A = A + eta_sr*(Rt - A)\n",
    "            B = B + eta_sr*(Rt*Rt - B)\n",
    "            # gradiente simplificado\n",
    "            dS_dRt = eta_sr*(1/np.sqrt(B) - (A*Rt)/(B**1.5 + 1e-12))\n",
    "            dz = np.zeros_like(w)\n",
    "            dz[:M] += X[t]\n",
    "            dz[M]  += prevF_cont\n",
    "            dz[M+1]+= 1.0\n",
    "            df_dz = 1 - np.tanh(z)**2\n",
    "            df_dw = df_dz * dz\n",
    "            dRt_dFprev = r[t]\n",
    "            dRt_dw = dRt_dFprev * df_dw\n",
    "            dL += dS_dRt * dRt_dw\n",
    "            prevF_cont = f_cont\n",
    "            prevF_exec = F_exec\n",
    "        w += lr * dL / (np.linalg.norm(dL)+1e-8)\n",
    "    return w\n",
    "\n",
    "w = train(X, r, epochs)\n",
    "\n",
    "prevF_exec = 0.0\n",
    "equity = [1.0]\n",
    "for t in range(len(X)):\n",
    "    f_cont, F_exec, _ = policy(X[t], np.tanh(0.0 if t==0 else 0.5))\n",
    "    Rt = prevF_exec*r[t] - delta*abs(F_exec - prevF_exec)\n",
    "    equity.append(equity[-1]*(1+Rt))\n",
    "    prevF_exec = F_exec\n",
    "\n",
    "print(\"Equity final:\", equity[-1])\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
