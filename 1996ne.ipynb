{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c8b86f-1005-4fe6-b6bc-c973a69ed5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class TwoAssetMarket:\n",
    "    def __init__(self, mu=0.0005, phi=0.1, vol_base=0.01, vol_persist=0.95, seed=0):\n",
    "        self.rng = np.random.default_rng(seed)\n",
    "        self.mu, self.phi, self.vol_base, self.vol_persist = mu, phi, vol_base, vol_persist\n",
    "        self.r_prev, self.sigma2 = 0.0, vol_base**2\n",
    "    def step(self):\n",
    "        eps = self.rng.normal()\n",
    "        self.sigma2 = self.vol_base**2 + 0.05*(self.r_prev**2) + self.vol_persist*self.sigma2\n",
    "        r = self.mu + self.phi*self.r_prev + np.sqrt(abs(self.sigma2))*eps\n",
    "        self.r_prev = r\n",
    "        return r\n",
    "\n",
    "class Neuneier96Env:\n",
    "    def __init__(self, k=10, grid_n=21, seed=0):\n",
    "        self.k=k; self.grid=np.linspace(0,1,grid_n); self.market=TwoAssetMarket(seed=seed)\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.buf=[0.0]*self.k; self.w_prev=0.0; self.wealth=1.0\n",
    "        return self._state()\n",
    "    def _state(self):\n",
    "        return np.array(self.buf+[self.w_prev], dtype=np.float32)\n",
    "    def step(self, a_idx):\n",
    "        w=float(self.grid[a_idx]); r=self.market.step()\n",
    "        port_r = w*r\n",
    "        self.wealth *= (1+port_r)\n",
    "        self.buf.pop(0); self.buf.append(r); self.w_prev=w\n",
    "        return self._state(), port_r, False, {}\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, state_dim, n_actions):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(state_dim,128), nn.ReLU(),\n",
    "            nn.Linear(128,128), nn.ReLU(),\n",
    "            nn.Linear(128,n_actions)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def train_neuneier96(steps=10000, gamma=0.99, lr=1e-3, batch=256, verbose=1000):\n",
    "    env=Neuneier96Env()\n",
    "    state_dim=len(env._state()); n_actions=len(env.grid)\n",
    "    q=QNet(state_dim,n_actions); qt=QNet(state_dim,n_actions); qt.load_state_dict(q.state_dict())\n",
    "    opt=optim.Adam(q.parameters(), lr=lr)\n",
    "    bufS,bufA,bufR,bufNS,bufD=[],[],[],[],[]\n",
    "    s=env.reset(); rng=np.random.default_rng(0); last_loss=None\n",
    "    \n",
    "    for t in range(steps):\n",
    "        eps=max(0.05, 1.0 - t/steps)\n",
    "        a = rng.integers(0,n_actions) if rng.random()<eps else q(torch.tensor(s).unsqueeze(0)).argmax(1).item()\n",
    "        ns,r,d,_=env.step(a)\n",
    "        bufS.append(s); bufA.append(a); bufR.append(r); bufNS.append(ns); bufD.append(d); s=ns\n",
    "        \n",
    "        if len(bufS)>=batch:\n",
    "            idx=rng.integers(0,len(bufS),size=batch)\n",
    "            S=torch.tensor([bufS[i] for i in idx],dtype=torch.float32)\n",
    "            A=torch.tensor([bufA[i] for i in idx],dtype=torch.long).unsqueeze(1)\n",
    "            R=torch.tensor([bufR[i] for i in idx],dtype=torch.float32).unsqueeze(1)\n",
    "            NS=torch.tensor([bufNS[i] for i in idx],dtype=torch.float32)\n",
    "            D=torch.tensor([bufD[i] for i in idx],dtype=torch.float32).unsqueeze(1)\n",
    "            with torch.no_grad():\n",
    "                an=q(NS).argmax(1,keepdim=True)\n",
    "                y=R+gamma*(1-D)*qt(NS).gather(1,an)\n",
    "            qvals=q(S).gather(1,A)\n",
    "            loss=(qvals-y).pow(2).mean()\n",
    "            opt.zero_grad(); loss.backward(); opt.step()\n",
    "            last_loss=float(loss.item())\n",
    "        \n",
    "        if verbose and (t % verbose == 0) and t>0:\n",
    "            print(f\"step {t}/{steps}  eps={eps:.2f}  loss={last_loss:.6f}\")\n",
    "    \n",
    "    return q\n",
    "\n",
    "def eval_policy(q, env=None, steps=1000):\n",
    "    if env is None: env = Neuneier96Env()\n",
    "    s = env.reset(); wealth = 1.0\n",
    "    for _ in range(steps):\n",
    "        with torch.no_grad():\n",
    "            a = q(torch.tensor(s).unsqueeze(0)).argmax(1).item()\n",
    "        s, r, _, _ = env.step(a)\n",
    "        wealth *= (1.0 + r)\n",
    "    print(f\"Wealth final ~ {wealth:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
